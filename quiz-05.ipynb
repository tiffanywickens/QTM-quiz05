{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f070b06",
   "metadata": {},
   "source": [
    "## Quiz 05 - Parallel Computing, Reproducibility, and Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6142c4",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "This quiz is based on the material covered in lectures 20 to 24. You may use\n",
    "any resources available to you, including the lecture notes and the internet.\n",
    "\n",
    "All the data required for this quiz can be found in the `data` folder within this repository. If you need to recreate the datasets, you can do so by running the Python script included in the `script-data-generation` folder.\n",
    "\n",
    "**Important:** Please start by completing Question 01 to set up the correct Python environment before proceeding with the other questions.\n",
    "\n",
    "This notebook contains the questions you need to answer.\n",
    "If possible, please submit your answers as an `.html` file on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47fa52",
   "metadata": {},
   "source": [
    "### **Question 01: Setting up the Python Environment**\n",
    "\n",
    "Before proceeding with the rest of the quiz, it is important to set up a Python environment with specific package versions to ensure compatibility and reproducibility. This quiz requires **Python 3.10** and the following packages with exact versions:\n",
    "- `dask-sql=2024.5.0`\n",
    "- `dask=2024.4.1`\n",
    "- `ipykernel=6.29.3`\n",
    "- `joblib=1.3.2`\n",
    "- `numpy=1.26.4`\n",
    "- `pandas=2.2.1`\n",
    "\n",
    "You can use tools like `conda`, `pipenv`, or `uv` to manage your environment. If you use conda (recommended), please make sure you **create the environment and install all packages in the same command**. Also include `-c conda-forge` in your command. Make sure to change your current environment to the new environment after creation. \n",
    "\n",
    "Write the terminal commands in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dbf581",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4174038818.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda create -n quiz05 python=3.10 \\\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Please write your bash commands here. You can run them using the `!` operator or the `%%bash` magic.\n",
    "conda create -n quiz05 python=3.10 \\\n",
    "  dask-sql=2024.5.0 \\\n",
    "  dask=2024.4.1 \\\n",
    "  ipykernel=6.29.3 \\\n",
    "  joblib=1.3.2 \\\n",
    "  numpy=1.26.4 \\\n",
    "  pandas=2.2.1 \\\n",
    "  -c conda-forge -y\n",
    "\n",
    "conda activate quiz05\n",
    "\n",
    "python -m ipykernel install --user --name quiz05 --display-name \"Python (quiz05)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8e018",
   "metadata": {},
   "source": [
    "### Question 02: Understanding the `map` Function and Parallelism\n",
    "\n",
    "The built-in Python `map()` function applies a function to each element sequentially. Using `joblib`, rewrite the following serial code to run in parallel using **all available cores** (hint: use `n_jobs=-1`). Compare the results to verify correctness.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def cube_root(x):\n",
    "    return x ** (1/3)\n",
    "\n",
    "numbers = np.arange(1, 500001)\n",
    "\n",
    "# Serial version using map\n",
    "serial_result = list(map(cube_root, numbers))\n",
    "print(\"First 5 serial results:\", serial_result[:5])\n",
    "```\n",
    "\n",
    "Write the parallel version using `joblib.Parallel` and `delayed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12eea799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 parallel results: [1.0, 1.2599210498948732, 1.4422495703074083, 1.5874010519681994, 1.7099759466766968]\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def cube_root(x):\n",
    "    return x ** (1/3)\n",
    "\n",
    "numbers = np.arange(1, 500001)\n",
    "\n",
    "parallel_result = Parallel(n_jobs=-1)(\n",
    "    delayed(cube_root)(x) for x in numbers\n",
    ")\n",
    "\n",
    "print(\"First 5 parallel results:\", parallel_result[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94ca03",
   "metadata": {},
   "source": [
    "### Question 03: Measuring Parallel Speedup\n",
    "\n",
    "Create a function called `simulate_computation` that generates 100,000 random numbers and calculates their variance. Using `%timeit`, measure and compare the execution time of:\n",
    "\n",
    "1. Running the function **4 times sequentially** in a list comprehension (`[simulate_computation() for _ in range(4)]`)\n",
    "2. Running the function **4 times in parallel** using `joblib` with 4 workers\n",
    "\n",
    "Print and compare both timing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f76ddaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05 ms ± 32.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "11.8 ms ± 949 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def simulate_computation():\n",
    "    data = np.random.rand(100_000)\n",
    "    return np.var(data)\n",
    "\n",
    "%timeit [simulate_computation() for _ in range(4)]\n",
    "\n",
    "%timeit Parallel(n_jobs=4)(delayed(simulate_computation)() for _ in range(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47889840",
   "metadata": {},
   "source": [
    "### Question 04: Dask Array with Custom Chunk Sizes\n",
    "\n",
    "Create a Dask array of shape (5000, 2000) filled with random integers between 1 and 100. Use chunks of size (500, 500). Then:\n",
    "\n",
    "1. Compute the sum of each row\n",
    "2. Calculate the mean and standard deviation of the entire array\n",
    "3. Print all three results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd325641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100263  99816 100242 ... 101373 101490 103403]\n",
      "50.5113081\n",
      "28.86255744259116\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import dask.array as da\n",
    "\n",
    "x = da.random.randint(1, 101, size=(5000, 2000), chunks=(500, 500))\n",
    "\n",
    "row_sums = x.sum(axis=1).compute()\n",
    "\n",
    "mean_val = x.mean().compute()\n",
    "std_val = x.std().compute()\n",
    "\n",
    "print(row_sums)\n",
    "print(mean_val)\n",
    "print(std_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be770baf",
   "metadata": {},
   "source": [
    "### Question 05: Optimising Chunk Size\n",
    "\n",
    "The chunk size significantly affects Dask performance. Create a Dask array with 100,000 random numbers and test three different chunk sizes: 1,000 (many small chunks), 10,000 (medium chunks), and 50,000 (few large chunks).\n",
    "\n",
    "For each configuration, measure the time to compute `mean(sin(x) + cos(x))`. Which chunk size performed best? Explain why in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5163e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size 1000: 0.0387 seconds\n",
      "Chunk size 10000: 0.0065 seconds\n",
      "Chunk size 50000: 0.0045 seconds\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "chunk_sizes = [1000, 10000, 50000]\n",
    "\n",
    "for cs in chunk_sizes:\n",
    "    x = da.random.random(100000, chunks=cs)\n",
    "    expr = da.mean(da.sin(x) + da.cos(x))\n",
    "    \n",
    "    start = time.time()\n",
    "    expr.compute()\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Chunk size {cs}: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f620cfde",
   "metadata": {},
   "source": [
    "### Question 06: Reading Parquet Files with Column Selection\n",
    "\n",
    "The `data` folder contains Parquet files for multiple countries. Using Dask, read **all Parquet files at once** (`data/*.parquet`), but load only the `year` and `population` columns.\n",
    "\n",
    "Calculate the total world population for each year across all countries and display the results sorted by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cc3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1945     566994202\n",
      "1946     596804909\n",
      "1947     606569895\n",
      "1948     637303888\n",
      "1949     644613118\n",
      "           ...    \n",
      "2019    1893887207\n",
      "2020    1959057915\n",
      "2021    1928046753\n",
      "2022    1985837056\n",
      "2023    1980706538\n",
      "Name: population, Length: 79, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_parquet(\"data/*.parquet\", columns=[\"year\", \"population\"])\n",
    "\n",
    "result = (\n",
    "    df.groupby(\"year\")[\"population\"]\n",
    "      .sum()\n",
    "      .compute()\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c5b75",
   "metadata": {},
   "source": [
    "### Question 07: Dask SQL with Multiple Conditions\n",
    "\n",
    "Load the `data.csv` file into a Dask DataFrame and register it as a SQL table. Write a SQL query that:\n",
    "\n",
    "1. Selects countries where `gdp_per_capita` was between 10000 and 50000\n",
    "2. Filters for years between 2000 and 2020\n",
    "3. Orders results by `gdp_per_capita` in descending order\n",
    "4. Limits to the top 2 results\n",
    "\n",
    "Execute the query and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32507297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country  year  gdp_per_capita  population\n",
      "294     USA  2002    48942.492140   284207485\n",
      "295     USA  2003    47607.365171   277711486\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask_sql import Context\n",
    "\n",
    "df = dd.read_csv(\"data/data.csv\")\n",
    "\n",
    "c = Context()\n",
    "c.create_table(\"gdp\", df)  # \"gdp\" is the table name we'll use in SQL\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM gdp\n",
    "WHERE gdp_per_capita BETWEEN 10000 AND 50000\n",
    "  AND year BETWEEN 2000 AND 2020\n",
    "ORDER BY gdp_per_capita DESC\n",
    "LIMIT 2\n",
    "\"\"\"\n",
    "\n",
    "result = c.sql(query).compute()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "### Question 08: Dask SQL with Aggregation\n",
    "\n",
    "Using the same `data.csv` file, write a SQL query that calculates:\n",
    "\n",
    "1. The average GDP per capita for each country\n",
    "2. The minimum and maximum years in the dataset for each country\n",
    "\n",
    "Group by country and display all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "954c2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country       avg_gdp  min_year  max_year\n",
      "0  Brazil   5496.292031      1945      2023\n",
      "1   India   1251.704443      1945      2023\n",
      "2      UK  27496.851363      1945      2023\n",
      "3     USA  40189.822290      1945      2023\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  country,\n",
    "  AVG(gdp_per_capita) AS avg_gdp,\n",
    "  MIN(year) AS min_year,\n",
    "  MAX(year) AS max_year\n",
    "FROM gdp\n",
    "GROUP BY country\n",
    "\"\"\"\n",
    "\n",
    "agg_result = c.sql(query).compute()\n",
    "print(agg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### Question 09: Generating `requirements.txt` and `environment.yml` Files\n",
    "\n",
    "Write the commands to:\n",
    "\n",
    "1. Export your current environment's packages to a `requirements.txt` and an `environment.yml` file\n",
    "2. Show how someone else would install these exact dependencies in these two cases\n",
    "\n",
    "Explain each step with comments. It is not necessary to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76ea9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3497796018.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip freeze > requirements.txt\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Please write your answer here.\n",
    "\n",
    "# Export all installed Python packages into a requirements.txt file.\n",
    "# This is basically a snapshot of the environment for pip users.\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "# Export the full conda environment, including package versions and channels,\n",
    "# to an environment.yml file. This is the “official” way to share conda envs.\n",
    "conda env export > environment.yml\n",
    "\n",
    "#2. Someone else wants to recreate this setup:\n",
    "\n",
    "# Install everything from requirements.txt using pip.\n",
    "# This recreates (almost) the same Python environment.\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Create a full conda environment from the YAML file.\n",
    "# This copies the environment almost exactly same versions, same packages.\n",
    "conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5438c",
   "metadata": {},
   "source": [
    "### Question 10: Troubleshooting a Broken Dockerfile\n",
    "\n",
    "The following Dockerfile has several errors. Identify and fix 5 issues, then explain what was wrong with each line:\n",
    "\n",
    "INCCORRECTED DOCKERFILE:\n",
    "```dockerfile\n",
    "# Broken Dockerfile - Fix the errors\n",
    "from ubuntu\n",
    "\n",
    "RUN apt install python3 python3-pip\n",
    "RUN pip install numpy pandas\n",
    "\n",
    "COPY . .\n",
    "EXPOSE 8888\n",
    "RUN [\"python3\", \"app.py\"]\n",
    "```\n",
    "CORRECTED DOCKERFILE:\n",
    "```dockerfile\n",
    "# 1. Use a proper base image name and tag\n",
    "FROM ubuntu:24.04\n",
    "\n",
    "# 2. Install Python and pip in a single RUN, update first, and clean up\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y python3 python3-pip && \\\n",
    "    apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# 3. Set a working directory for the app\n",
    "WORKDIR /app\n",
    "\n",
    "# 4. Copy project files into the image\n",
    "COPY . .\n",
    "\n",
    "# 5. Install Python dependencies\n",
    "RUN pip3 install numpy pandas\n",
    "\n",
    "# 6. Expose the port the app will run on\n",
    "EXPOSE 8888\n",
    "\n",
    "# 7. Use CMD so this runs when the container starts\n",
    "CMD [\"python3\", \"app.py\"]\n",
    "```\n",
    "Write the corrected Dockerfile and list each error with its fix.\n",
    "1. from ubuntu\n",
    "Instruction keyword should be uppercase: FROM, not from. No tag specified (ubuntu instead of something like ubuntu:24.04), which hurts reproducibility.\n",
    "\n",
    "2. RUN apt install python3 python3-pip\n",
    "Problems: Uses apt instead of apt-get, which is what Docker docs and the course use, it doesn’t run apt-get update first, so package metadata may be stale. Also, missing -y so the build can hang waiting for interactive confirmation.\n",
    "\n",
    "3. RUN pip install numpy pandas\n",
    "Problems: Uses bare pip, which might be linked to the wrong Python, doesn’t avoid pip’s cache, which makes the image larger. Also, no clear place where the app lives (no WORKDIR yet), so it’s a bit messy.\n",
    "\n",
    "4. Missing WORKDIR before COPY . .\n",
    "Problem: Without a WORKDIR, COPY . . dumps files in the root of the filesystem (/), which is bad practice and confusing. The app has no clear home directory.\n",
    "\n",
    "5. RUN [\"python3\", \"app.py\"]\n",
    "Problem: RUN is a build-time instruction; it runs while the image is being built and then finishes. We want app.py to run when the container starts, not during the image build. For that we should use CMD (or ENTRYPOINT).\n",
    "\n",
    "There is still two issues that could be fixed:\n",
    "\n",
    "6. The Dockerfile installs packages using apt, but never clears the package lists or cache, which makes the final image significantly larger.\n",
    "\n",
    "7. Inconsistent/mixed RUN command styles (shell vs exec), and it can cause confusing differences in behavior; lecture recommends consistent shell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de7fd8",
   "metadata": {},
   "source": [
    "### Question 11 - Writing a Dockerfile to Install Software on a Base Image\n",
    "\n",
    "Create a Dockerfile that starts from an Ubuntu image and installs the following software:\n",
    "\n",
    "- Git version 2.43.0-1ubuntu7.1\n",
    "- SQLite version 3.45.1-1ubuntu2\n",
    "\n",
    "Ensure that you specify the exact versions of the packages by checking their versions after installation. Include commands to clean up the package manager cache after installation to reduce the image size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c602292",
   "metadata": {},
   "source": [
    "#### Please write your anwer here. You can use ```dockerfile to format your code\n",
    "\n",
    "```dockerfile\n",
    "FROM ubuntu:24.04\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y \\\n",
    "        git=1:2.43.0-1ubuntu7.1 \\\n",
    "        sqlite3=3.45.1-1ubuntu2 \\\n",
    "        libsqlite3-0=3.45.1-1ubuntu2 && \\\n",
    "    git --version && \\\n",
    "    sqlite3 --version && \\\n",
    "    apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7354df6",
   "metadata": {},
   "source": [
    "### Question 12: Dockerfile for a Jupyter Data Science Environment\n",
    "\n",
    "Create a Dockerfile starting from Ubuntu that:\n",
    "\n",
    "1. Installs Python 3.11 and pip\n",
    "2. Installs `jupyterlab`, `numpy`, `pandas`, `matplotlib`, and `scikit-learn` with specific versions of your choice\n",
    "4. Sets the working directory to `/home/analyst/notebooks`\n",
    "5. Exposes port 8888\n",
    "6. Starts JupyterLab with `--no-browser` and `--ip=0.0.0.0`\n",
    "\n",
    "Clean up apt cache to reduce image size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9c49e",
   "metadata": {},
   "source": [
    "#### Please write your answer here. You can use ```dockerfile to format your code\n",
    "\n",
    "```dockerfile\n",
    "FROM ubuntu:24.04\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y python3.11 python3.11-venv python3-pip && \\\n",
    "    apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "WORKDIR /home/analyst/notebooks\n",
    "\n",
    "RUN python3.11 -m pip install --no-cache-dir \\\n",
    "    jupyterlab \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    matplotlib \\\n",
    "    scikit-learn\n",
    "\n",
    "EXPOSE 8888\n",
    "\n",
    "CMD [\"jupyter\", \"lab\", \"--no-browser\", \"--ip=0.0.0.0\", \"--notebook-dir=/home/analyst/notebooks\", \"--allow-root\"]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quiz05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
